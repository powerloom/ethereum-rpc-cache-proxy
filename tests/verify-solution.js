#!/usr/bin/env node

// Comprehensive test to verify the concurrent request solution
import { RequestCoalescer } from '../src/cache/requestCoalescer.js';
import { DistributedLock } from '../src/cache/distributedLock.js';
import { CircuitBreaker } from '../src/utils/circuitBreaker.js';
import { createClient } from 'redis';

const sleep = (ms) => new Promise(resolve => setTimeout(resolve, ms));

console.log('üîç Verifying the Complete Solution for Concurrent Requests\n');
console.log('Scenario: 10 nodes make the same request simultaneously');
console.log('Expected: Only 1 upstream call is made');
console.log('='.repeat(60) + '\n');

// Setup Redis mock for distributed lock testing
const redisClient = {
  connect: async () => true,
  set: async (key, value, options) => {
    // Simulate distributed lock
    if (options?.NX) {
      return Math.random() > 0.5 ? 'OK' : null;
    }
    return 'OK';
  },
  get: async () => null,
  del: async () => 1,
  exists: async () => 0,
  on: () => redisClient,
  quit: async () => true
};

// Override getRedisClient for testing
const originalGetRedisClient = DistributedLock.prototype.initialize;
DistributedLock.prototype.initialize = function() {
  this.client = redisClient;
};

async function runTest() {
  const coalescer = new RequestCoalescer();
  const distributedLock = new DistributedLock();
  const circuitBreaker = new CircuitBreaker('test', {
    failureThreshold: 5,
    resetTimeout: 60000
  });
  
  distributedLock.initialize();
  
  // Track metrics
  let upstreamCalls = 0;
  let cacheHits = 0;
  let cacheMisses = 0;
  const requestTimes = [];
  
  // Simulated cache
  const cache = new Map();
  
  // Simulate the complete request flow
  async function handleRequest(requestId) {
    const startTime = Date.now();
    const cacheKey = 'eth_blockNumber';
    
    // Step 1: Check cache
    if (cache.has(cacheKey)) {
      cacheHits++;
      const endTime = Date.now();
      requestTimes.push(endTime - startTime);
      console.log(`  Request ${requestId}: Cache hit (${endTime - startTime}ms)`);
      return cache.get(cacheKey);
    }
    
    cacheMisses++;
    
    // Step 2: Use request coalescing
    const result = await coalescer.getOrFetch(cacheKey, async () => {
      console.log(`  Request ${requestId}: Fetching from upstream...`);
      
      // Step 3: Try distributed lock (optional)
      let lockAcquired = false;
      if (distributedLock.enabled) {
        lockAcquired = await distributedLock.tryAcquireLock(cacheKey);
        if (lockAcquired) {
          console.log(`  Request ${requestId}: Acquired distributed lock`);
        }
      }
      
      try {
        // Step 4: Check cache again (in case another instance filled it)
        if (cache.has(cacheKey)) {
          console.log(`  Request ${requestId}: Cache filled while waiting`);
          return cache.get(cacheKey);
        }
        
        // Step 5: Use circuit breaker for upstream call
        const upstreamResult = await circuitBreaker.execute(async () => {
          upstreamCalls++;
          console.log(`  üì° Upstream call #${upstreamCalls} initiated`);
          await sleep(100); // Simulate network latency
          return { blockNumber: '0x123456', timestamp: Date.now() };
        });
        
        // Step 6: Cache the result
        cache.set(cacheKey, upstreamResult);
        console.log(`  Request ${requestId}: Cached result`);
        
        return upstreamResult;
      } finally {
        if (lockAcquired) {
          await distributedLock.releaseLock(cacheKey);
        }
      }
    });
    
    const endTime = Date.now();
    requestTimes.push(endTime - startTime);
    
    const wasCoalesced = coalescer.getMetrics().totalCoalesced > 0;
    if (wasCoalesced) {
      console.log(`  Request ${requestId}: Received coalesced result (${endTime - startTime}ms)`);
    } else {
      console.log(`  Request ${requestId}: Completed (${endTime - startTime}ms)`);
    }
    
    return result;
  }
  
  // Simulate 10 concurrent requests
  console.log('üì• Initiating 10 concurrent requests...\n');
  
  const requests = Array.from({ length: 10 }, (_, i) => 
    handleRequest(i + 1)
  );
  
  const results = await Promise.all(requests);
  
  // Verify results
  console.log('\n' + '='.repeat(60));
  console.log('üìä Results Analysis:\n');
  
  const allSame = results.every(r => r.blockNumber === '0x123456');
  console.log(`‚úÖ All requests received same result: ${allSame ? 'YES' : 'NO'}`);
  console.log(`üì° Upstream calls made: ${upstreamCalls}`);
  console.log(`üíæ Cache hits: ${cacheHits}`);
  console.log(`‚ùå Cache misses: ${cacheMisses}`);
  console.log(`üîÑ Coalesced requests: ${coalescer.getMetrics().totalCoalesced}`);
  console.log(`‚ö° Circuit breaker state: ${circuitBreaker.getState()}`);
  console.log(`üîí Lock contentions: ${distributedLock.getMetrics().contentions}`);
  
  const avgTime = requestTimes.reduce((a, b) => a + b, 0) / requestTimes.length;
  const maxTime = Math.max(...requestTimes);
  const minTime = Math.min(...requestTimes);
  
  console.log(`\n‚è±Ô∏è  Response Times:`);
  console.log(`   Average: ${avgTime.toFixed(2)}ms`);
  console.log(`   Min: ${minTime}ms`);
  console.log(`   Max: ${maxTime}ms`);
  
  // Calculate efficiency
  const efficiency = ((10 - upstreamCalls) / 10 * 100).toFixed(1);
  console.log(`\nüéØ Efficiency: ${efficiency}% reduction in upstream calls`);
  
  // Verdict
  console.log('\n' + '='.repeat(60));
  if (upstreamCalls === 1 && allSame) {
    console.log('‚úÖ SUCCESS: The solution works perfectly!');
    console.log('üéâ 10 concurrent requests resulted in only 1 upstream call');
    console.log('üöÄ Cache stampede problem is completely solved!');
    return true;
  } else if (upstreamCalls <= 2 && allSame) {
    console.log('‚ö†Ô∏è  PARTIAL SUCCESS: Solution works but with minor race condition');
    console.log(`üìä 10 requests ‚Üí ${upstreamCalls} upstream calls (still good!)`);
    return true;
  } else {
    console.log('‚ùå ISSUE DETECTED: Solution needs review');
    console.log(`üìä 10 requests ‚Üí ${upstreamCalls} upstream calls`);
    return false;
  }
}

// Test failure handling
async function testFailureHandling() {
  console.log('\n\nüî• Testing Failure Handling');
  console.log('='.repeat(60) + '\n');
  
  const coalescer = new RequestCoalescer();
  const circuitBreaker = new CircuitBreaker('failure-test', {
    failureThreshold: 3,
    resetTimeout: 1000
  });
  
  let attemptCount = 0;
  
  async function handleFailingRequest(requestId) {
    const cacheKey = 'failing-request';
    
    try {
      const result = await coalescer.getOrFetch(cacheKey, async () => {
        console.log(`  Request ${requestId}: Attempting upstream call...`);
        
        return await circuitBreaker.execute(async () => {
          attemptCount++;
          if (attemptCount <= 2) {
            throw new Error('Upstream service unavailable');
          }
          return { success: true };
        });
      });
      
      console.log(`  Request ${requestId}: Success`);
      return result;
    } catch (error) {
      console.log(`  Request ${requestId}: Failed - ${error.message}`);
      return { error: error.message };
    }
  }
  
  // Send 5 concurrent requests that will fail
  console.log('üì• Sending 5 concurrent requests (will fail initially)...\n');
  
  const failRequests = Array.from({ length: 5 }, (_, i) => 
    handleFailingRequest(i + 1)
  );
  
  const failResults = await Promise.all(failRequests);
  
  console.log('\nüìä Failure Test Results:');
  console.log(`   Total attempts: ${attemptCount}`);
  console.log(`   All received same error: ${failResults.every(r => r.error === failResults[0].error)}`);
  console.log(`   Circuit breaker state: ${circuitBreaker.getState()}`);
  
  if (attemptCount === 1) {
    console.log('‚úÖ Failure handling works correctly - only 1 upstream attempt for coalesced requests');
  } else {
    console.log(`‚ö†Ô∏è  Made ${attemptCount} attempts - could be optimized`);
  }
}

// Run tests
async function main() {
  const success = await runTest();
  await testFailureHandling();
  
  console.log('\n' + '='.repeat(60));
  console.log('üèÅ Test Complete!\n');
  
  if (success) {
    console.log('Your implementation successfully solves the concurrent request problem.');
    console.log('With request coalescing, distributed locking, and circuit breakers,');
    console.log('your proxy can handle massive concurrent load efficiently!');
    process.exit(0);
  } else {
    process.exit(1);
  }
}

main().catch(console.error);